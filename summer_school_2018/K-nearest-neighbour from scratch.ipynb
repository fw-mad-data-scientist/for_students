{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest-neighbours alogrithm\n",
    "The aim of this exercise is to get knowledge of how kNN algorithm exactly work by developing it from scratch on simple Iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "Our exercise has several steps:\n",
    "1. getting the iris dataset\n",
    "2. converting the dataset to pandas format\n",
    "3. splitting dataset into train/test part\n",
    "4. defining distance metric - we are going to use euclidean one\n",
    "5. creating a function that will find nearest neighbours for given example\n",
    "6. predicting the specie value for each observation in train set and assess the classifiaction error\n",
    "7. predicting the specie value for each observation in test set\n",
    "8. Investigating confusion matrix\n",
    "9. Analyzing test error based on different k parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# we remove the scientific notation to be displayed\n",
    "np.set_printoptions(suppress=True)\n",
    "# we set up the float format for pandas\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting iris dataset\n",
    "Firstly we need to get data. To do this we can use one of sklearn's packages called dataset - this is the only one place where we will use sklearn in this notebook ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the data with .data property. The target variable (which tells us about the specie of particular observation) is accessed with .target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.9,  3. ,  5.1,  1.8]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Converting the dataset to pandas format\n",
    "\n",
    "We have loaded python's arrays containing both features and target variable. Our aim for now is to merge them into one pandas DataFrame as it is basic data structure for data analysis and machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.DataFrame(iris['data'], columns=iris['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating DataFrame we should add the column with target variable. Let's call it 'target' and assign the array with target to the DataFrame created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df['target'] = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's shuffle data. You can do it multiple ways:\n",
    "* sample (DataFrame property) with fraction argument set to be 1\n",
    "* shuffle function from sklearn.utils package\n",
    "* np.random.shuffle function (it should take np.ndarray, so you should pass DF.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = iris_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With typical DF properties we can examine the structure of the iris dataset. You should show:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* first five elements from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.700</td>\n",
       "      <td>2.800</td>\n",
       "      <td>4.100</td>\n",
       "      <td>1.300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.200</td>\n",
       "      <td>3.400</td>\n",
       "      <td>5.400</td>\n",
       "      <td>2.300</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.600</td>\n",
       "      <td>2.500</td>\n",
       "      <td>3.900</td>\n",
       "      <td>1.100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.600</td>\n",
       "      <td>3.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.100</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0              5.700             2.800              4.100             1.300   \n",
       "1              6.200             3.400              5.400             2.300   \n",
       "2              5.600             2.500              3.900             1.100   \n",
       "3              4.600             3.600              1.000             0.200   \n",
       "4              5.100             3.500              1.400             0.300   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       2  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* last five elements from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.500</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.200</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.500</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.800</td>\n",
       "      <td>2.200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.200</td>\n",
       "      <td>2.800</td>\n",
       "      <td>4.800</td>\n",
       "      <td>1.800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5.000</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1.300</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>4.800</td>\n",
       "      <td>3.100</td>\n",
       "      <td>1.600</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "145              6.500             3.000              5.200             2.000   \n",
       "146              6.500             3.000              5.800             2.200   \n",
       "147              6.200             2.800              4.800             1.800   \n",
       "148              5.000             3.500              1.300             0.300   \n",
       "149              4.800             3.100              1.600             0.200   \n",
       "\n",
       "     target  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       0  \n",
       "149       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a short statistical summary of all variables in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000</td>\n",
       "      <td>150.000</td>\n",
       "      <td>150.000</td>\n",
       "      <td>150.000</td>\n",
       "      <td>150.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843</td>\n",
       "      <td>3.054</td>\n",
       "      <td>3.759</td>\n",
       "      <td>1.199</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.434</td>\n",
       "      <td>1.764</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100</td>\n",
       "      <td>2.800</td>\n",
       "      <td>1.600</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4.350</td>\n",
       "      <td>1.300</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400</td>\n",
       "      <td>3.300</td>\n",
       "      <td>5.100</td>\n",
       "      <td>1.800</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900</td>\n",
       "      <td>4.400</td>\n",
       "      <td>6.900</td>\n",
       "      <td>2.500</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count            150.000           150.000            150.000   \n",
       "mean               5.843             3.054              3.759   \n",
       "std                0.828             0.434              1.764   \n",
       "min                4.300             2.000              1.000   \n",
       "25%                5.100             2.800              1.600   \n",
       "50%                5.800             3.000              4.350   \n",
       "75%                6.400             3.300              5.100   \n",
       "max                7.900             4.400              6.900   \n",
       "\n",
       "       petal width (cm)  target  \n",
       "count           150.000 150.000  \n",
       "mean              1.199   1.000  \n",
       "std               0.763   0.819  \n",
       "min               0.100   0.000  \n",
       "25%               0.300   0.000  \n",
       "50%               1.300   1.000  \n",
       "75%               1.800   2.000  \n",
       "max               2.500   2.000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Splitting dataset into train/test part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a typical Machine Learning pipeline you should divide your dataset into two parts:\n",
    "* train - it will be used to train the model (note that for k-nn algorithm there is no actual process of training - it is just computing the distance matrix between all observations)\n",
    "* test - this part will be hold out of training process and will serve to assess the algorithms performance\n",
    "\n",
    "You can do it in a few ways:\n",
    "* train_test_split from sklearn package\n",
    "* .sample method for DataFrame objects\n",
    "* create a logical mask that would indicate wheter observations will be in train (TRUE) or test (FALSE) set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraction = 0.8\n",
    "\n",
    "# mask should be a logical array of dtype=bool that has about 80% of True values. How can we do that?\n",
    "mask = np.random.rand(len(iris_df)) < train_fraction\n",
    "\n",
    "# we apply mask on original dataset\n",
    "train = iris_df[mask]\n",
    "test = iris_df[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reset and remove (drop argument) index from frames, as this is not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Defining distance metric - we are going to use euclidean one\n",
    "We need to create a function called 'euclidean_distance' that will return distance for given pair of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(array_1, array_2):\n",
    "    # we need to create a distance function\n",
    "    # it takes as inputs two numpy arrays each representing one object:\n",
    "    # euclidean_distance = (x1 - y1) ^ 2 + (x2 - y2) ^ 2 + ... + (xn - yn) ^ 2\n",
    "    # tip: it is pretty simple using vectorised operations in numpy\n",
    "    # function euclidean_distance should return one numerical value\n",
    "    differences = array_1 - array_2\n",
    "    differences_squared = differences ** 2\n",
    "    # now we can add up all the differences squared\n",
    "    distance = np.sum(differences_squared)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. creating a function that will find nearest neighbours for given example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example row from distance matrix\n",
    "Let us tak a look into one observation and create the whole process of finding *k* similar observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)   6.200\n",
       "sepal width (cm)    3.400\n",
       "petal length (cm)   5.400\n",
       "petal width (cm)    2.300\n",
       "target              2.000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first row of train dataset\n",
    "train.iloc[0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8600000000000012"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets compute distance between first and second observation\n",
    "# note! you should remove the last variable called 'target' - we use only first four features\n",
    "euclidean_distance(train.iloc[0, 0:4], train.iloc[1, 0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the distance between 4th and 5th element in train dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.33\n"
     ]
    }
   ],
   "source": [
    "distance_4_5 = euclidean_distance(train.iloc[3, 0:4], train.iloc[4, 0:4])\n",
    "print(distance_4_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute all distances to first observation. We create an empty list, and then iterating by all training examples we append it with the distance between them and first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance from element no. 0 to element no. 0 is 0.0\n",
      "Distance from element no. 0 to element no. 1 is 4.860000000000001\n",
      "Distance from element no. 0 to element no. 2 is 26.370000000000005\n",
      "Distance from element no. 0 to element no. 3 is 21.220000000000002\n",
      "Distance from element no. 0 to element no. 4 is 0.3899999999999998\n",
      "Distance from element no. 0 to element no. 5 is 4.660000000000001\n",
      "Distance from element no. 0 to element no. 6 is 1.7400000000000004\n",
      "Distance from element no. 0 to element no. 7 is 0.6200000000000008\n",
      "Distance from element no. 0 to element no. 8 is 17.230000000000004\n",
      "Distance from element no. 0 to element no. 9 is 20.520000000000003\n",
      "Distance from element no. 0 to element no. 10 is 4.850000000000001\n",
      "Distance from element no. 0 to element no. 11 is 22.270000000000003\n",
      "Distance from element no. 0 to element no. 12 is 20.070000000000004\n",
      "Distance from element no. 0 to element no. 13 is 4.110000000000001\n",
      "Distance from element no. 0 to element no. 14 is 1.469999999999999\n",
      "Distance from element no. 0 to element no. 15 is 18.19\n",
      "Distance from element no. 0 to element no. 16 is 20.810000000000002\n",
      "Distance from element no. 0 to element no. 17 is 2.1499999999999995\n",
      "Distance from element no. 0 to element no. 18 is 23.9\n",
      "Distance from element no. 0 to element no. 19 is 8.790000000000001\n",
      "Distance from element no. 0 to element no. 20 is 5.13\n",
      "Distance from element no. 0 to element no. 21 is 2.2799999999999994\n",
      "Distance from element no. 0 to element no. 22 is 0.5099999999999996\n",
      "Distance from element no. 0 to element no. 23 is 21.720000000000006\n",
      "Distance from element no. 0 to element no. 24 is 0.45\n",
      "Distance from element no. 0 to element no. 25 is 1.9700000000000009\n",
      "Distance from element no. 0 to element no. 26 is 4.109999999999999\n",
      "Distance from element no. 0 to element no. 27 is 0.3899999999999996\n",
      "Distance from element no. 0 to element no. 28 is 6.07\n",
      "Distance from element no. 0 to element no. 29 is 2.94\n",
      "Distance from element no. 0 to element no. 30 is 1.4699999999999998\n",
      "Distance from element no. 0 to element no. 31 is 3.34\n",
      "Distance from element no. 0 to element no. 32 is 0.6200000000000001\n",
      "Distance from element no. 0 to element no. 33 is 0.6499999999999995\n",
      "Distance from element no. 0 to element no. 34 is 21.89\n",
      "Distance from element no. 0 to element no. 35 is 3.210000000000002\n",
      "Distance from element no. 0 to element no. 36 is 23.009999999999998\n",
      "Distance from element no. 0 to element no. 37 is 1.3400000000000003\n",
      "Distance from element no. 0 to element no. 38 is 22.259999999999998\n",
      "Distance from element no. 0 to element no. 39 is 2.8899999999999997\n",
      "Distance from element no. 0 to element no. 40 is 2.0500000000000003\n",
      "Distance from element no. 0 to element no. 41 is 3.2199999999999998\n",
      "Distance from element no. 0 to element no. 42 is 22.57\n",
      "Distance from element no. 0 to element no. 43 is 1.5600000000000003\n",
      "Distance from element no. 0 to element no. 44 is 18.150000000000002\n",
      "Distance from element no. 0 to element no. 45 is 2.4499999999999993\n",
      "Distance from element no. 0 to element no. 46 is 20.35\n",
      "Distance from element no. 0 to element no. 47 is 0.62\n",
      "Distance from element no. 0 to element no. 48 is 1.0600000000000007\n",
      "Distance from element no. 0 to element no. 49 is 0.39\n",
      "Distance from element no. 0 to element no. 50 is 24.910000000000007\n",
      "Distance from element no. 0 to element no. 51 is 18.620000000000005\n",
      "Distance from element no. 0 to element no. 52 is 0.9000000000000002\n",
      "Distance from element no. 0 to element no. 53 is 0.09000000000000007\n",
      "Distance from element no. 0 to element no. 54 is 18.740000000000002\n",
      "Distance from element no. 0 to element no. 55 is 24.5\n",
      "Distance from element no. 0 to element no. 56 is 0.9999999999999993\n",
      "Distance from element no. 0 to element no. 57 is 2.25\n",
      "Distance from element no. 0 to element no. 58 is 1.7099999999999995\n",
      "Distance from element no. 0 to element no. 59 is 0.5499999999999994\n",
      "Distance from element no. 0 to element no. 60 is 23.53\n",
      "Distance from element no. 0 to element no. 61 is 3.599999999999997\n",
      "Distance from element no. 0 to element no. 62 is 3.9700000000000006\n",
      "Distance from element no. 0 to element no. 63 is 21.409999999999997\n",
      "Distance from element no. 0 to element no. 64 is 20.22\n",
      "Distance from element no. 0 to element no. 65 is 1.9799999999999998\n",
      "Distance from element no. 0 to element no. 66 is 21.54\n",
      "Distance from element no. 0 to element no. 67 is 0.7400000000000002\n",
      "Distance from element no. 0 to element no. 68 is 0.3899999999999997\n",
      "Distance from element no. 0 to element no. 69 is 2.899999999999999\n",
      "Distance from element no. 0 to element no. 70 is 21.830000000000002\n",
      "Distance from element no. 0 to element no. 71 is 18.78\n",
      "Distance from element no. 0 to element no. 72 is 0.9299999999999999\n",
      "Distance from element no. 0 to element no. 73 is 2.129999999999999\n",
      "Distance from element no. 0 to element no. 74 is 20.450000000000003\n",
      "Distance from element no. 0 to element no. 75 is 0.9999999999999998\n",
      "Distance from element no. 0 to element no. 76 is 18.1\n",
      "Distance from element no. 0 to element no. 77 is 3.2900000000000005\n",
      "Distance from element no. 0 to element no. 78 is 0.6700000000000006\n",
      "Distance from element no. 0 to element no. 79 is 4.260000000000001\n",
      "Distance from element no. 0 to element no. 80 is 19.46\n",
      "Distance from element no. 0 to element no. 81 is 0.5699999999999994\n",
      "Distance from element no. 0 to element no. 82 is 20.580000000000005\n",
      "Distance from element no. 0 to element no. 83 is 1.8900000000000003\n",
      "Distance from element no. 0 to element no. 84 is 0.41999999999999965\n",
      "Distance from element no. 0 to element no. 85 is 0.8100000000000004\n",
      "Distance from element no. 0 to element no. 86 is 3.330000000000001\n",
      "Distance from element no. 0 to element no. 87 is 0.05999999999999966\n",
      "Distance from element no. 0 to element no. 88 is 2.519999999999998\n",
      "Distance from element no. 0 to element no. 89 is 1.14\n",
      "Distance from element no. 0 to element no. 90 is 21.540000000000003\n",
      "Distance from element no. 0 to element no. 91 is 21.14\n",
      "Distance from element no. 0 to element no. 92 is 1.7300000000000009\n",
      "Distance from element no. 0 to element no. 93 is 0.6699999999999998\n",
      "Distance from element no. 0 to element no. 94 is 21.630000000000003\n",
      "Distance from element no. 0 to element no. 95 is 0.9000000000000002\n",
      "Distance from element no. 0 to element no. 96 is 21.830000000000002\n",
      "Distance from element no. 0 to element no. 97 is 4.140000000000001\n",
      "Distance from element no. 0 to element no. 98 is 3.06\n",
      "Distance from element no. 0 to element no. 99 is 2.4200000000000004\n",
      "Distance from element no. 0 to element no. 100 is 2.33\n",
      "Distance from element no. 0 to element no. 101 is 23.510000000000005\n",
      "Distance from element no. 0 to element no. 102 is 2.500000000000001\n",
      "Distance from element no. 0 to element no. 103 is 21.86\n",
      "Distance from element no. 0 to element no. 104 is 1.6499999999999992\n",
      "Distance from element no. 0 to element no. 105 is 1.4699999999999998\n",
      "Distance from element no. 0 to element no. 106 is 21.310000000000006\n",
      "Distance from element no. 0 to element no. 107 is 4.030000000000001\n",
      "Distance from element no. 0 to element no. 108 is 0.3100000000000001\n",
      "Distance from element no. 0 to element no. 109 is 20.120000000000005\n",
      "Distance from element no. 0 to element no. 110 is 1.569999999999999\n",
      "Distance from element no. 0 to element no. 111 is 5.14\n",
      "Distance from element no. 0 to element no. 112 is 1.5300000000000002\n",
      "Distance from element no. 0 to element no. 113 is 0.37999999999999984\n",
      "Distance from element no. 0 to element no. 114 is 0.9700000000000005\n",
      "Distance from element no. 0 to element no. 115 is 22.260000000000005\n",
      "Distance from element no. 0 to element no. 116 is 20.9\n"
     ]
    }
   ],
   "source": [
    "distances_to_first_element = []\n",
    "number_of_elements_in_train_frame = train.shape[0]\n",
    "\n",
    "for i in range(0, number_of_elements_in_train_frame):\n",
    "    # compute distance between FIRST and I-TH observation in training set \n",
    "    distance = euclidean_distance(train.iloc[0, 0:4], train.iloc[i, 0:4])\n",
    "    ### append the computed distance to distances_to_first_element list\n",
    "    distances_to_first_element.append(distance)\n",
    "    print('Distance from element no. 0 to element no. {} is {}'.format(i, distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the list looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 4.8600000000000012, 26.370000000000005, 21.220000000000002, 0.38999999999999979, 4.660000000000001, 1.7400000000000004, 0.62000000000000077, 17.230000000000004, 20.520000000000003, 4.8500000000000014, 22.270000000000003, 20.070000000000004, 4.1100000000000012, 1.4699999999999991, 18.190000000000001, 20.810000000000002, 2.1499999999999995, 23.899999999999999, 8.7900000000000009, 5.1299999999999999, 2.2799999999999994, 0.50999999999999956, 21.720000000000006, 0.45000000000000001, 1.9700000000000009, 4.1099999999999994, 0.38999999999999962, 6.0700000000000003, 2.9399999999999999, 1.4699999999999998, 3.3399999999999999, 0.62000000000000011, 0.64999999999999947, 21.890000000000001, 3.2100000000000022, 23.009999999999998, 1.3400000000000003, 22.259999999999998, 2.8899999999999997, 2.0500000000000003, 3.2199999999999998, 22.57, 1.5600000000000003, 18.150000000000002, 2.4499999999999993, 20.350000000000001, 0.62, 1.0600000000000007, 0.39000000000000001, 24.910000000000007, 18.620000000000005, 0.90000000000000024, 0.090000000000000066, 18.740000000000002, 24.5, 0.99999999999999933, 2.25, 1.7099999999999995, 0.54999999999999938, 23.530000000000001, 3.599999999999997, 3.9700000000000006, 21.409999999999997, 20.219999999999999, 1.9799999999999998, 21.539999999999999, 0.74000000000000021, 0.38999999999999968, 2.899999999999999, 21.830000000000002, 18.780000000000001, 0.92999999999999994, 2.129999999999999, 20.450000000000003, 0.99999999999999978, 18.100000000000001, 3.2900000000000005, 0.6700000000000006, 4.2600000000000007, 19.460000000000001, 0.5699999999999994, 20.580000000000005, 1.8900000000000003, 0.41999999999999965, 0.81000000000000039, 3.330000000000001, 0.059999999999999658, 2.5199999999999978, 1.1399999999999999, 21.540000000000003, 21.140000000000001, 1.7300000000000009, 0.66999999999999982, 21.630000000000003, 0.90000000000000024, 21.830000000000002, 4.1400000000000006, 3.0600000000000001, 2.4200000000000004, 2.3300000000000001, 23.510000000000005, 2.5000000000000009, 21.859999999999999, 1.6499999999999992, 1.4699999999999998, 21.310000000000006, 4.0300000000000011, 0.31000000000000011, 20.120000000000005, 1.569999999999999, 5.1399999999999997, 1.5300000000000002, 0.37999999999999984, 0.97000000000000053, 22.260000000000005, 20.899999999999999]\n"
     ]
    }
   ],
   "source": [
    "print(distances_to_first_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 'target_variable' which is the LIST of values showing target variable. Note: pandas series has a tolist() method which can be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 0, 0, 2, 1, 1, 2, 0, 0, 1, 0, 0, 1, 2, 0, 0, 1, 0, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 1, 1, 2, 0, 2, 1, 0, 0, 1, 0, 1, 2, 2, 0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 0, 2, 0, 1, 2, 2, 1, 2, 2, 2, 0, 0, 1, 2, 0, 2, 0, 2, 1, 1, 1, 0, 1, 0, 2, 1, 0, 1, 2, 0, 2, 2, 1, 2, 2, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "target_variable = train['target'].tolist()\n",
    "print(target_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should create a list of tuples with following structure:\n",
    "[\n",
    "(distance1, specie1),\n",
    "(distance2, specie2)\n",
    "...\n",
    "(distance_n, specie_n)\n",
    "] and sort it by distance\n",
    "Find below snippet example on how to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'p'), (1, 'y'), (2, 't'), (3, 'h'), (4, 'o'), (5, 'n')]\n"
     ]
    }
   ],
   "source": [
    "letters = ['y', 'h', 'p', 't', 'n', 'o']\n",
    "order = [1, 3, 0, 2, 5, 4]\n",
    "print(sorted(zip(order,letters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_target_combined = sorted(zip(distances_to_first_element, target_variable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get first three elements of such sorted list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 2), (0.059999999999999658, 2), (0.090000000000000066, 2)]\n"
     ]
    }
   ],
   "source": [
    "three_closest_tuples = distances_target_combined[0:3]\n",
    "print(three_closest_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a list comprehension to create a list with species only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "target_closest_species = [target for distance, target in three_closest_tuples]\n",
    "print(target_closest_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of Counter class (collections packages) we can count occurences for each specie class in given subset of three closest neighbours. You can see the example of usage below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted Counter({14: 3, 33: 2, 12: 1, 8: 1, 9: 1})\n",
      "Majority [(14, 3), (33, 2), (12, 1), (8, 1), (9, 1)]\n",
      "Most common class 14\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "sample_list =  [33, 33, 12, 14, 14, 14, 8, 9]\n",
    "counted = Counter(sample_list)\n",
    "print('Counted {}'.format(counted))\n",
    "ordered = counted.most_common()\n",
    "print('Majority {}'.format(ordered))\n",
    "most_common_value = ordered[0][0]\n",
    "print('Most common class {}'.format(most_common_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we know how to do it we should find the most common class within the neighbours classes stored in *target_closest_species* variable. We can then know which class will be assigned to analyzed example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "predicted_class = Counter(target_closest_species).most_common()[0][0]\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a pipeline for one observation - now we can create a function that can be used quickly to all cases. Write a function that takes number of neighbours *k* (integer), *element* (one row from dataframe), *dataset* (pandas dataframe with all observations), and list of ground truth annotations for the dataset (species) - *target list*. It should return a list of ground truth classes for k-nearest-neighbours (for example: [0,2,2,1] for k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap it into a function\n",
    "def find_k_closest_examples(k, element, dataset, target_list):\n",
    "    distances_to_element = []\n",
    "    for i in range(0, dataset.shape[0]):\n",
    "        distance = euclidean_distance(element, dataset.iloc[i, 0:4])\n",
    "        distances_to_element.append(distance)\n",
    "    \n",
    "    distances_target_combined = sorted(zip(distances_to_element, target_list))\n",
    "    species = [specie for distance, specie in distances_target_combined]\n",
    "    return species[0:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that takes a list with classes number for k-nearest-neighbours and outputs the most common class (use Counter class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_frequent_class(k_closest_examples):\n",
    "    predicted_class = Counter(k_closest_examples).most_common()[0][0]\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the prediction for k=5 for first observation in train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_frequent_class(find_k_closest_examples(5, train.iloc[0, ], train, train['target'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predicting the specie value for each observation in train set and assess the classifiaction error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write a for loop that will iterate over all training examples, and creates predictions for k = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 0, 0, 2, 1, 1, 2, 0, 0, 1, 0, 0, 1, 2, 0, 0, 1, 0, 1, 1, 1, 2, 0, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 1, 2, 2, 0, 2, 1, 0, 0, 1, 0, 2, 2, 2, 0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 0, 2, 0, 1, 2, 2, 1, 2, 2, 2, 0, 0, 1, 2, 0, 2, 0, 2, 1, 1, 1, 0, 1, 0, 2, 1, 0, 1, 2, 0, 2, 2, 1, 2, 2, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for i in range(0, train.shape[0]):\n",
    "    closest_examples = find_k_closest_examples(3, train.iloc[i,], train, train['target'].tolist())\n",
    "    most_frequent_class_for_i_neighbours = get_most_frequent_class(closest_examples)\n",
    "    predictions.append(most_frequent_class_for_i_neighbours)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a *classification_accuracy* function that takes predictions (in pd.Series format), and target_variable (also in pd.Series format) and return the classification error - the percentage of cases assigned properly by the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy(prediction_series, target_series):\n",
    "    is_correct = prediction_series == target_series\n",
    "    accuracy = np.sum(is_correct) / len(prediction_series)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97435897435897434"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_accuracy(pd.Series(predictions), train['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Predicting the specie value for each observation in test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now iterate over all TEST cases, find similar elements in train sample, and get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = []\n",
    "\n",
    "for i in range(0, test.shape[0]):\n",
    "    closest_examples = find_k_closest_examples(2, test.iloc[i,], train, train['target'].tolist())\n",
    "    predictions_test.append(get_most_frequent_class(closest_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 2, 0, 2, 2, 1, 0, 2, 1, 1, 0, 0, 2, 2, 1, 0, 1, 1, 0, 1, 0, 0, 2, 0, 1, 1, 1, 2, 0, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(predictions_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check test accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90909090909090906"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_accuracy(pd.Series(predictions_test), test['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Investigating confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0, 10,  2],\n",
       "       [ 0,  1, 10]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(pd.Series(predictions_test), test['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Analyzing test error based on different k parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracies = []\n",
    "\n",
    "for k in range(1, 15):\n",
    "    predictions_test = []\n",
    "    for i in range(0, test.shape[0]):\n",
    "        closest_examples = find_k_closest_examples(k, test.iloc[i,], train, train['target'].tolist())\n",
    "        predictions_test.append(get_most_frequent_class(closest_examples))\n",
    "    test_accuracies.append(classification_accuracy(pd.Series(predictions_test), test['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90909090909090906, 0.90909090909090906, 0.93939393939393945, 0.93939393939393945, 0.93939393939393945, 0.90909090909090906, 0.93939393939393945, 0.90909090909090906, 0.93939393939393945, 0.93939393939393945, 0.93939393939393945, 0.93939393939393945, 0.93939393939393945, 0.93939393939393945]\n"
     ]
    }
   ],
   "source": [
    "print(test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x9a91ef0>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x978ecf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(test_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
